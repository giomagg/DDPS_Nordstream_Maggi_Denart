1. Data Collection â€“ R Code

# Load packages (packages for second R part already included)
library(readxl)
library(dplyr)
library(reactable)
library(glue)
library(stringr)
library(httpuv)
library(ggplot2)
library(readr)
library(tidytext)
library(tidyverse)
library(SnowballC)
library(quanteda)
library(sjPlot)
library(magrittr)
library(ggplot2)
library(academictwitteR)
library(data.table)
library(igraph)
library(lubridate)

# Connect to Academic Twitter API and collect data (personal key for privacy reasons removed)
nordstream_tweets <- get_all_tweets(query = c("#NordStream"), 
                                start_tweets = "2022-09-26T00:00:00Z", 
                                end_tweets = "2023-03-12T00:00:00Z",
                                data_path = "data/",
                                bind_tweets = FALSE,
                                n = Inf)

# Transform dataset into easier-to-read format and save as CSV
tweets <- bind_tweets(data_path = "data/")
tidy_tweet_df <- bind_tweets(data_path = "data/", output_format = "tidy")
write_as_csv(
  tidy_tweet_df, file_name = "20230312_Nordstream_df.csv", 
  prepend_ids = TRUE, na = "", 
  fileEncoding = "UTF-8"
)
